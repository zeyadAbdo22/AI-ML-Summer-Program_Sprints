{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca206c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # read file csv..\n",
    "import numpy as np # import numpy package for linear algbra\n",
    "import re # regular expressions pakage,use for text processing\n",
    "from string import punctuation # to remove punctations\n",
    "import nltk # pakage use for nutural language\n",
    "from nltk.corpus import stopwords # package to handel stop words\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys # pakage used for handel the recursion limit\n",
    "from nltk.stem import PorterStemmer # import pakage for sttemming\n",
    "from sklearn.model_selection import train_test_split  # split data \n",
    "import torch  # Importing PyTorch, a deep learning framework\n",
    "import torch.nn as nn  # Importing PyTorch's neural network module\n",
    "import math  # Importing math for mathematical operations\n",
    "import torchtext  # Importing torchtext for text processing \n",
    "from torch.utils.data import DataLoader, TensorDataset  # Importing DataLoader and TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer  # Importing get_tokenizer \n",
    "from sklearn.metrics import accuracy_score  # to calculat accuarcy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77153393",
   "metadata": {},
   "source": [
    "## bulid model :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f611b",
   "metadata": {},
   "source": [
    "![Example Image](https://www.researchgate.net/profile/Joe-Meyer/publication/346737150/figure/fig5/AS:966593613938689@1607465284958/Transformer-Network-Vaswani-et-al-2017-This-particular-model-presented-in-the.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac945692",
   "metadata": {},
   "source": [
    "- A Transformer-based text classification model is a deep learning architecture that excels at processing and understanding sequential data like text. It uses self-attention mechanisms to capture dependencies between words in a sentence, enabling it to learn contextual information effectively. The model takes in a sequence of words as input and outputs a classification label, making it suitable for tasks such as sentiment analysis, spam detection, and language translation. Transformers have become a state-of-the-art choice for text classification due to their ability to capture long-range dependencies and their parallel processing capabilities, making them highly efficient for natural language understanding tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5954a",
   "metadata": {},
   "source": [
    "###  Class ScaledDotProductAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97686bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k  # Dimension of each head's key, query, and value\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # Compute attention scores\n",
    "        attn_scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9) \n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1) # use softmax to get attention probabilities\n",
    "        output = torch.matmul(attn_probs, value) # Multiply probabilities by value tensor\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911803a",
   "metadata": {},
   "source": [
    "- It takes input query, key, and value tensors, calculates attention scores, applies optional masking, computes attention probabilities using softmax, and produces an output representing the attended information from the input. The module is widely used in natural language processing and sequence-to-sequence tasks for tasks like machine translation, text generation, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd076c9",
   "metadata": {},
   "source": [
    "### class PositionWiseFeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef51b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):   \n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        # First linear layer\n",
    "        self.layer1 = nn.Linear(d_model, d_ff) \n",
    "         # Second linear layer  \n",
    "        self.layer2 = nn.Linear(d_ff, d_model) \n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU() \n",
    "       \n",
    "    def forward(self, x):        \n",
    "        hidden = self.relu(self.layer1(x)) # Apply ReLU on first linear layer output\n",
    "        output = self.layer2(hidden)       # Second linear layer \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbecc667",
   "metadata": {},
   "source": [
    "- This code class called PositionWiseFeedForward used in transformer-based models. It performs a position-wise feedforward transformation on input tensors, allowing the model to capture complex patterns. It consists of two linear layers with a ReLU activation function in between, transforming the input tensor from a lower-dimensional space (d_model) to a higher-dimensional space (d_ff) and then back to the original dimension (d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e352a9c",
   "metadata": {},
   "source": [
    "### class LinearLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d6670ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayers(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(LinearLayers, self).__init__()\n",
    "        # Linear transformations for query, key, value, and output\n",
    "        self.query_transform = nn.Linear(d_model, d_model)\n",
    "        self.key_transform = nn.Linear(d_model, d_model)\n",
    "        self.value_transform = nn.Linear(d_model, d_model)\n",
    "        self.output_transform = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7cea8",
   "metadata": {},
   "source": [
    "- This class called LinearLayers for linear transformations used in self-attention mechanisms within transformer-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78989c7",
   "metadata": {},
   "source": [
    "### class MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d35d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        # Ensure that the model dimension is divisible by the number of attention heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Store the model dimension and the number of attention heads\n",
    "        self.d_model = d_model            \n",
    "        self.num_heads = num_heads        \n",
    "        \n",
    "        # Calculate the dimension of each head's key, query, and value\n",
    "        self.d_k = d_model // num_heads  \n",
    "        \n",
    "        # Initialize linear transformations \n",
    "        self.linear_layers = LinearLayers(d_model)  \n",
    "        \n",
    "        # Initialize the Scaled Dot-Product Attention mechanism\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "        \n",
    "        # Reshape the input tensor to create multiple heads\n",
    "        x = x.view(batch_size, seq_length, self.num_heads, self.d_k)\n",
    "        \n",
    "        # Transpose dimensions \n",
    "        return x.transpose(1, 2)\n",
    "    \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, _ = x.size()\n",
    "        \n",
    "        # Transpose dimensions\n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "        \n",
    "        # Reshape the combined tensor\n",
    "        return x.view(batch_size, seq_length, self.d_model)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # Apply linear transformations \n",
    "        query = self.split_heads(self.linear_layers.query_transform(query))\n",
    "        key = self.split_heads(self.linear_layers.key_transform(key))\n",
    "        value = self.split_heads(self.linear_layers.value_transform(value))\n",
    "        \n",
    "        # Calculate attention scores \n",
    "        attn_output = self.attention(query, key, value, mask)\n",
    "        \n",
    "        # Combine the attention outputs \n",
    "        output = self.linear_layers.output_transform(self.combine_heads(attn_output))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb58732",
   "metadata": {},
   "source": [
    "- This class called MultiHeadAttention for implementing multi-head self-attention, a crucial component in transformer-based models. It takes query, key, and value tensors as input, applies linear transformations to these tensors to project them into multiple heads,computes scaled dot-product attention for each head, and then combines and projects the results back to the original dimension.This enables the model to simultaneously focus on different parts of the input sequence, capturing complex patterns and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232fe737",
   "metadata": {},
   "source": [
    "### class EncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85ca8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):    \n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()    \n",
    "        # Self-attention mechanism\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
    "        # Position-wise feed-forward neural network\n",
    "        self.positionwise_feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        # Layer normalization for the first sub-layer\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        # Layer normalization for the Second sub-layer\n",
    "        self.norm2 = nn.LayerNorm(d_model)  \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):   \n",
    "        # Self-attention and residual connection\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout(attn_output)   \n",
    "        # Layer normalization\n",
    "        x = self.norm1(x)\n",
    "        # Position-wise feed-forward neural network and residual connection\n",
    "        ffn_output = self.positionwise_feed_forward(x)        \n",
    "        x = x + self.dropout(ffn_output)\n",
    "        # Layer normalization\n",
    "        x = self.norm2(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954a7e1",
   "metadata": {},
   "source": [
    "- This code defines an EncoderLayer class for use in a Transformer-based neural network. An EncoderLayer represents one layer within the encoder stack of a Transformer model. It consists of the following components:\n",
    "\n",
    "1. Self-Attention Mechanism: The layer includes a self-attention mechanism (implemented using nn.MultiheadAttention) that calculates attention scores for the input sequence, allowing the model to focus on different parts of the input sequence.\n",
    "\n",
    "2. Position-Wise Feed-Forward Network: After the self-attention step, the layer applies a position-wise feed-forward neural network to the output of the self-attention step. This step introduces non-linearity and is followed by residual connections.\n",
    "\n",
    "3. Layer Normalization: Layer normalization is applied both after the self-attention step (self.norm1) and after the position-wise feed-forward step (self.norm2). Layer normalization helps stabilize training by ensuring that input values to each layer have similar mean and variance.\n",
    "\n",
    "4. Dropout: Dropout is applied for regularization purposes after both the self-attention step and the position-wise feed-forward step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf4d84",
   "metadata": {},
   "source": [
    "### class Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88cf0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):    \n",
    "    def __init__(self, d_model, max_seq_length, dropout):\n",
    "        super(Encoder, self).__init__()        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Calculate positional encodings\n",
    "        position_encoding = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)  \n",
    "        # Calculate div_term used in the positional encodings\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        # Calculate sine and cosine positional encodings\n",
    "        position_encoding[:, 0::2] = torch.sin(position * div_term)       \n",
    "        position_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "         # Register the positional encodings as a buffer\n",
    "        self.register_buffer('position_encoding', position_encoding.unsqueeze(0))     \n",
    "    def forward(self, x):\n",
    "        seq_length = x.size(1)  \n",
    "        x = x + self.position_encoding[:, :seq_length, :]    # Add positional encodings to the input\n",
    "        x = self.dropout(x)        # Apply dropout\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2dff2",
   "metadata": {},
   "source": [
    "- This code defines an Encoder module for a Transformer-based neural network. Its primary purpose is to process input sequences by adding positional encodings and applying dropout. Here's a concise summary:\n",
    "\n",
    "1. Initialization ( init method):\n",
    "   - Initializes the Encoder module with parameters like hidden dimension (d_model), maximum sequence length (max_seq_length), and dropout rate (dropout).\n",
    "   - Computes positional encodings for input sequences, which represent the order of tokens within the sequence and registers them as a buffer.\n",
    "\n",
    "2. Forward Pass (forward method):\n",
    "   - Takes an input tensor x of shape (batch_size, seq_length, d_model).\n",
    "   - Adds positional encodings to the input tensor to convey positional information.\n",
    "   - Applies dropout to the modified tensor for regularization.\n",
    "   - Returns the modified tensor as the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368cdc67",
   "metadata": {},
   "source": [
    "###  class DecoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34fcdc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):    \n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()    \n",
    "        # Self-attention layer\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
    "        # Encoder-decoder attention layer\n",
    "        self.enc_dec_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout) \n",
    "        # Position-wise feed-forward neural network\n",
    "        self.positionwise_feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)        \n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)  \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x, enc_output):   \n",
    "        # Self-attention\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout(attn_output)        \n",
    "        x = self.norm1(x)\n",
    "        # Encoder-decoder attention\n",
    "        enc_dec_attn_output, _ = self.enc_dec_attn(x, enc_output, enc_output)        \n",
    "        x = x + self.dropout(enc_dec_attn_output)\n",
    "        x = self.norm2(x)  \n",
    "        # Position-wise feed-forward neural network\n",
    "        ffn_output = self.positionwise_feed_forward(x)\n",
    "        x = x + self.dropout(ffn_output)        \n",
    "        x = self.norm3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6240019",
   "metadata": {},
   "source": [
    "- This code defines a DecoderLayer for a Transformer model. It processes input through self-attention, encoder-decoder attention, and a feed-forward network with residual connections and normalization. Multiple layers of this module are stacked to form the Transformer's decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b2d19",
   "metadata": {},
   "source": [
    "### class TransformerPredictionToxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f03671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPredictionToxic(nn.Module):    \n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, dropout, max_seq_length):        \n",
    "        super(TransformerPredictionToxic, self).__init__()    \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        # Positional encoding layer\n",
    "        self.positional_encoding = Encoder(d_model, max_seq_length, dropout)   \n",
    "        # Encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        # Decoder layers\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])   \n",
    "        # Fully connected layer for prediction\n",
    "        self.fc = nn.Linear(d_model, 2)  # 2 classes: toxic or not toxic\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout\n",
    "    def forward(self, x):  \n",
    "        # Embedding and positional encoding\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)  \n",
    "        # Encoder layers\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer(x)        \n",
    "        # Decoder layers    \n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            x = decoder_layer(x, x)      \n",
    "        # Global average pooling    \n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = self.fc(x)    # Fully connected layer for prediction    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121447e",
   "metadata": {},
   "source": [
    "- This code defines a Transformer-based neural network model named TransformerPredictionToxic for binary text classification, specifically for identifying whether a text is toxic or not. The model takes text as input, applies embeddings and positional encodings, processes it through encoder and decoder layers, and produces a toxicity prediction using a fully connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1805c01d",
   "metadata": {},
   "source": [
    "## read data and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b03d37",
   "metadata": {},
   "source": [
    "- read data and apply clean to handel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fd2f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data by read_csv\n",
    "df = pd.read_csv(r\"D:\\The University\\Level 2\\tranning\\sprints\\6\\0\\train.csv\")\n",
    "# show all data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed2d4ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fc112",
   "metadata": {},
   "source": [
    "- all col int but comment_text is obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b769e8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "337ecbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show duplicated data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80481d12",
   "metadata": {},
   "source": [
    "- no missing and duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43fbef",
   "metadata": {},
   "source": [
    "## clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e628ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean col comment_text \n",
    "def clean_text(text):\n",
    "    # create lower case\n",
    "    text = text.lower()\n",
    "    # remove url\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s\\d]', ' ', text)\n",
    "    # handle problem as (can't ,didn't , it's)\n",
    "    text = re.sub(r\"([a-zA-Z]+)'([a-zA-Z]+)\", r\"\\1 \\2\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d5deb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation\\nwhy the edits made under my usern...\n",
       "1         d aww  he matches this background colour i m s...\n",
       "2         hey man  i m really not trying to edit war  it...\n",
       "3          \\nmore\\ni can t make any real suggestions on ...\n",
       "4         you  sir  are my hero  any chance you remember...\n",
       "                                ...                        \n",
       "159566          and for the second time of asking  when ...\n",
       "159567    you should be ashamed of yourself \\n\\nthat is ...\n",
       "159568    spitzer \\n\\numm  theres no actual article for ...\n",
       "159569    and it looks like it was actually you who put ...\n",
       "159570     \\nand     i really don t think you understand...\n",
       "Name: comment_text_handel, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function on col comment_text\n",
    "df['comment_text_handel'] = df['comment_text'].apply(clean_text)\n",
    "# show col comment_text_handel\n",
    "df['comment_text_handel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c951f6",
   "metadata": {},
   "source": [
    "## stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f00d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords') # download stopwords becuase not found\n",
    "# Create a set of stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#Function to remove stop words comment_text col\n",
    "def remove_stopwords_text(text):\n",
    "  #split text for applay stop words\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d963cc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation edits made username hardcore metal...\n",
       "1         aww matches background colour seemingly stuck ...\n",
       "2         hey man really trying edit war guy constantly ...\n",
       "3         make real suggestions improvement wondered sec...\n",
       "4                             sir hero chance remember page\n",
       "                                ...                        \n",
       "159566    second time asking view completely contradicts...\n",
       "159567    ashamed horrible thing put talk page 128 61 19 93\n",
       "159568    spitzer umm theres actual article prostitution...\n",
       "159569    looks like actually put speedy first version d...\n",
       "159570    really think understand came idea bad right aw...\n",
       "Name: comment_text_handel, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply function on comment_text_handel\n",
    "df['comment_text_handel'] = df['comment_text_handel'].apply(remove_stopwords_text)\n",
    "#show col comment_text_handel\n",
    "df['comment_text_handel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b42db0",
   "metadata": {},
   "source": [
    "- now col is clean(no punctuation no stopwords) applay tokinzation to apply train model easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3415186",
   "metadata": {},
   "source": [
    "## toknization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90334a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "# Function to tokenize comment_text col\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10af9d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [explanation, edits, made, username, hardcore,...\n",
       "1         [aww, matches, background, colour, seemingly, ...\n",
       "2         [hey, man, really, trying, edit, war, guy, con...\n",
       "3         [make, real, suggestions, improvement, wondere...\n",
       "4                       [sir, hero, chance, remember, page]\n",
       "                                ...                        \n",
       "159566    [second, time, asking, view, completely, contr...\n",
       "159567    [ashamed, horrible, thing, put, talk, page, 12...\n",
       "159568    [spitzer, umm, theres, actual, article, prosti...\n",
       "159569    [looks, like, actually, put, speedy, first, ve...\n",
       "159570    [really, think, understand, came, idea, bad, r...\n",
       "Name: comment_text_handel, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function on comment_text_handel\n",
    "df['comment_text_handel'] = df['comment_text_handel'].apply(tokenize_text)\n",
    "# show col comment_text_handel\n",
    "df['comment_text_handel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406c7a6",
   "metadata": {},
   "source": [
    "- apply toknization data is ready to stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1eaf3d",
   "metadata": {},
   "source": [
    "## stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28a9be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handel the recursion limit\n",
    "sys.setrecursionlimit(10**6)\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "# Function to apply stemming to a list of words\n",
    "def stemmming_text(words):\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eafe1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explan edit made usernam hardcor metallica fan...\n",
       "1         aww match background colour seemingli stuck th...\n",
       "2         hey man realli tri edit war guy constantli rem...\n",
       "3         make real suggest improv wonder section statis...\n",
       "4                                sir hero chanc rememb page\n",
       "                                ...                        \n",
       "159566    second time ask view complet contradict covera...\n",
       "159567       asham horribl thing put talk page 128 61 19 93\n",
       "159568    spitzer umm there actual articl prostitut ring...\n",
       "159569    look like actual put speedi first version dele...\n",
       "159570    realli think understand came idea bad right aw...\n",
       "Name: comment_text_handel_2, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function on comment_text_handel\n",
    "df['comment_text_handel_2'] = df['comment_text_handel'].apply(stemmming_text)\n",
    "# show col comment_text_handel\n",
    "df['comment_text_handel_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb0646",
   "metadata": {},
   "source": [
    "# copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de6e5395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text_handel</th>\n",
       "      <th>comment_text_handel_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>explan edit made usernam hardcor metallica fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[aww, matches, background, colour, seemingly, ...</td>\n",
       "      <td>aww match background colour seemingli stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "      <td>hey man realli tri edit war guy constantli rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
       "      <td>make real suggest improv wonder section statis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>sir hero chanc rememb page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[second, time, asking, view, completely, contr...</td>\n",
       "      <td>second time ask view complet contradict covera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ashamed, horrible, thing, put, talk, page, 12...</td>\n",
       "      <td>asham horribl thing put talk page 128 61 19 93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[spitzer, umm, theres, actual, article, prosti...</td>\n",
       "      <td>spitzer umm there actual articl prostitut ring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[looks, like, actually, put, speedy, first, ve...</td>\n",
       "      <td>look like actual put speedi first version dele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[really, think, understand, came, idea, bad, r...</td>\n",
       "      <td>realli think understand came idea bad right aw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0           0             0        0       0       0              0   \n",
       "1           0             0        0       0       0              0   \n",
       "2           0             0        0       0       0              0   \n",
       "3           0             0        0       0       0              0   \n",
       "4           0             0        0       0       0              0   \n",
       "...       ...           ...      ...     ...     ...            ...   \n",
       "159566      0             0        0       0       0              0   \n",
       "159567      0             0        0       0       0              0   \n",
       "159568      0             0        0       0       0              0   \n",
       "159569      0             0        0       0       0              0   \n",
       "159570      0             0        0       0       0              0   \n",
       "\n",
       "                                      comment_text_handel  \\\n",
       "0       [explanation, edits, made, username, hardcore,...   \n",
       "1       [aww, matches, background, colour, seemingly, ...   \n",
       "2       [hey, man, really, trying, edit, war, guy, con...   \n",
       "3       [make, real, suggestions, improvement, wondere...   \n",
       "4                     [sir, hero, chance, remember, page]   \n",
       "...                                                   ...   \n",
       "159566  [second, time, asking, view, completely, contr...   \n",
       "159567  [ashamed, horrible, thing, put, talk, page, 12...   \n",
       "159568  [spitzer, umm, theres, actual, article, prosti...   \n",
       "159569  [looks, like, actually, put, speedy, first, ve...   \n",
       "159570  [really, think, understand, came, idea, bad, r...   \n",
       "\n",
       "                                    comment_text_handel_2  \n",
       "0       explan edit made usernam hardcor metallica fan...  \n",
       "1       aww match background colour seemingli stuck th...  \n",
       "2       hey man realli tri edit war guy constantli rem...  \n",
       "3       make real suggest improv wonder section statis...  \n",
       "4                              sir hero chanc rememb page  \n",
       "...                                                   ...  \n",
       "159566  second time ask view complet contradict covera...  \n",
       "159567     asham horribl thing put talk page 128 61 19 93  \n",
       "159568  spitzer umm there actual articl prostitut ring...  \n",
       "159569  look like actual put speedi first version dele...  \n",
       "159570  realli think understand came idea bad right aw...  \n",
       "\n",
       "[159571 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy data to be esay for handel code\n",
    "data = df.copy()\n",
    "#show data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0d362",
   "metadata": {},
   "source": [
    "- copy data to be easy acsses code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdffded",
   "metadata": {},
   "source": [
    "### create sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f61d362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text_handel</th>\n",
       "      <th>comment_text_handel_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26556</th>\n",
       "      <td>465ca8af0afcd303</td>\n",
       "      <td>You seem to be trying to push a certain POV on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[seem, trying, push, certain, pov, article, pl...</td>\n",
       "      <td>seem tri push certain pov articl pleas see wp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126994</th>\n",
       "      <td>a72a66073995bbab</td>\n",
       "      <td>Why would Emma be dressed as the pagan greek g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[would, emma, dressed, pagan, greek, goddess, ...</td>\n",
       "      <td>would emma dress pagan greek goddess cybel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99205</th>\n",
       "      <td>12a8bb9ac50c72ee</td>\n",
       "      <td>\"\\nI'd say Zivo Blato is not heavy metal but h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[say, zivo, blato, heavy, metal, hard, rock, a...</td>\n",
       "      <td>say zivo blato heavi metal hard rock although ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33426</th>\n",
       "      <td>59223dc85dfaa2ce</td>\n",
       "      <td>\"\\nI think you mean delete, not delite. /Mid (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[think, mean, delete, delite, mid, contributions]</td>\n",
       "      <td>think mean delet delit mid contribut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77559</th>\n",
       "      <td>cfcb3cb0ab661f6b</td>\n",
       "      <td>Thanks for quietly indicating I wasn't paying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[thanks, quietly, indicating, paying, proper, ...</td>\n",
       "      <td>thank quietli indic pay proper attent exchang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127526</th>\n",
       "      <td>aa0df73f3c66be2c</td>\n",
       "      <td>\"\\n\\nPlease do not be condescending and uncivi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[please, condescending, uncivil, comments, lik...</td>\n",
       "      <td>pleas condescend uncivil comment like sure dut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124496</th>\n",
       "      <td>9a026cf66647da22</td>\n",
       "      <td>Mr. Break Grant Talk Page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[mr, break, grant, talk, page]</td>\n",
       "      <td>mr break grant talk page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23034</th>\n",
       "      <td>3ce643b1a8648906</td>\n",
       "      <td>\"\\nAs an internationalist who wants nothing mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[internationalist, wants, nothing, equal, chan...</td>\n",
       "      <td>internationalist want noth equal chanc everyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40650</th>\n",
       "      <td>6c80d1b1752f00e9</td>\n",
       "      <td>\"\\nThanks, I see that the permission has been ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[thanks, see, permission, handled, talk]</td>\n",
       "      <td>thank see permiss handl talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83649</th>\n",
       "      <td>dfda7a021d5be62d</td>\n",
       "      <td>Your deleting unbiased facts . Clean up the pu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleting, unbiased, facts, clean, punctuation...</td>\n",
       "      <td>delet unbias fact clean punctuat leav referenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1595 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "26556   465ca8af0afcd303  You seem to be trying to push a certain POV on...   \n",
       "126994  a72a66073995bbab  Why would Emma be dressed as the pagan greek g...   \n",
       "99205   12a8bb9ac50c72ee  \"\\nI'd say Zivo Blato is not heavy metal but h...   \n",
       "33426   59223dc85dfaa2ce  \"\\nI think you mean delete, not delite. /Mid (...   \n",
       "77559   cfcb3cb0ab661f6b  Thanks for quietly indicating I wasn't paying ...   \n",
       "...                  ...                                                ...   \n",
       "127526  aa0df73f3c66be2c  \"\\n\\nPlease do not be condescending and uncivi...   \n",
       "124496  9a026cf66647da22                          Mr. Break Grant Talk Page   \n",
       "23034   3ce643b1a8648906  \"\\nAs an internationalist who wants nothing mo...   \n",
       "40650   6c80d1b1752f00e9  \"\\nThanks, I see that the permission has been ...   \n",
       "83649   dfda7a021d5be62d  Your deleting unbiased facts . Clean up the pu...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "26556       0             0        0       0       0              0   \n",
       "126994      0             0        0       0       0              0   \n",
       "99205       0             0        1       0       0              0   \n",
       "33426       0             0        0       0       0              0   \n",
       "77559       0             0        0       0       0              0   \n",
       "...       ...           ...      ...     ...     ...            ...   \n",
       "127526      0             0        0       0       0              0   \n",
       "124496      0             0        0       0       0              0   \n",
       "23034       0             0        0       0       0              0   \n",
       "40650       0             0        0       0       0              0   \n",
       "83649       0             0        0       0       0              0   \n",
       "\n",
       "                                      comment_text_handel  \\\n",
       "26556   [seem, trying, push, certain, pov, article, pl...   \n",
       "126994  [would, emma, dressed, pagan, greek, goddess, ...   \n",
       "99205   [say, zivo, blato, heavy, metal, hard, rock, a...   \n",
       "33426   [think, mean, delete, delite, mid, contributions]   \n",
       "77559   [thanks, quietly, indicating, paying, proper, ...   \n",
       "...                                                   ...   \n",
       "127526  [please, condescending, uncivil, comments, lik...   \n",
       "124496                     [mr, break, grant, talk, page]   \n",
       "23034   [internationalist, wants, nothing, equal, chan...   \n",
       "40650            [thanks, see, permission, handled, talk]   \n",
       "83649   [deleting, unbiased, facts, clean, punctuation...   \n",
       "\n",
       "                                    comment_text_handel_2  \n",
       "26556   seem tri push certain pov articl pleas see wp ...  \n",
       "126994         would emma dress pagan greek goddess cybel  \n",
       "99205   say zivo blato heavi metal hard rock although ...  \n",
       "33426                think mean delet delit mid contribut  \n",
       "77559   thank quietli indic pay proper attent exchang ...  \n",
       "...                                                   ...  \n",
       "127526  pleas condescend uncivil comment like sure dut...  \n",
       "124496                           mr break grant talk page  \n",
       "23034   internationalist want noth equal chanc everyon...  \n",
       "40650                        thank see permiss handl talk  \n",
       "83649   delet unbias fact clean punctuat leav referenc...  \n",
       "\n",
       "[1595 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the size of the sample (at least 40% of the original data)\n",
    "#sample_size = max(len(data) * 4 // 100, 1)   #  ***not working on my pc\n",
    "sample_size = max(len(data) * 1 // 100, 1)\n",
    "# Randomly select rows to create the sample DataFrame\n",
    "sample_df = data.sample(n=sample_size)\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be4670",
   "metadata": {},
   "source": [
    "- select 40% from data to apply train model but is not work on my pc then i select 1 % from data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c1ce2e",
   "metadata": {},
   "source": [
    "### function numericalize_with_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e431a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maximum sequence \n",
    "max_seq_length = 100  \n",
    "\n",
    "# Function to numericalize tokens with padding\n",
    "def numericalize_with_padding(tokens):\n",
    "    numericalized = [vocab[token] for token in tokens]  \n",
    "    padded = numericalized[:max_seq_length] + [0] * (max_seq_length - len(numericalized))  # padding the squence\n",
    "    return torch.tensor(padded)\n",
    "# Tokenize and stem the comments\n",
    "tokenized_comments = sample_df[\"comment_text_handel\"]\n",
    "# Build vocabulary from tokenized comments\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_comments)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7173a1",
   "metadata": {},
   "source": [
    "- create this function to change comment_text_handel from text to number to apply model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a16230",
   "metadata": {},
   "source": [
    "###  split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a305edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized comments to numerical format with padding \n",
    "numericalized_comments = [numericalize_with_padding(tokens) for tokens in tokenized_comments]\n",
    "# Prepare data for training and evaluation\n",
    "labels = sample_df['toxic']\n",
    "# split data into (train and test) data\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(numericalized_comments, labels, test_size = 0.2, train_size= 0.4, stratify = sample_df['toxic'], random_state=42)\n",
    "# Convert the training and evaluation data to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.stack(X_train), torch.tensor(y_train.to_numpy()))\n",
    "test_dataset = TensorDataset(torch.stack(X_eval), torch.tensor(y_eval.to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5bf220",
   "metadata": {},
   "source": [
    "- Now split data is ready to apply train model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c70bf4",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3409e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5475, Accuracy: 83.70%\n",
      "Epoch: 2, Loss: 0.3238, Accuracy: 90.60%\n",
      "Epoch: 3, Loss: 0.3221, Accuracy: 90.60%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Transformer model\n",
    "\n",
    "# Model dimensionality\n",
    "d_model = 256  \n",
    "# Number of attention heads\n",
    "num_heads = 4 \n",
    "# Number of encoder and decoder layers\n",
    "num_layers = 4    \n",
    "# Dimension of the feed-forward network\n",
    "d_ff = 512   \n",
    "# Dropout rate for regularization\n",
    "dropout = 0.2      \n",
    "# Batch size for training\n",
    "batch_size = 64  \n",
    "# Learning rate for optimizer\n",
    "learning_rate = 0.001 \n",
    "# Number of training epochs\n",
    "num_epochs = 3      \n",
    "\n",
    "# Build the Transformer model\n",
    "model = TransformerPredictionToxic(vocab_size, d_model, num_heads, num_layers, d_ff, dropout, max_seq_length)\n",
    "# Use Adam optimizer for training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Define the loss function (CrossEntropyLoss for classification tasks)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create train_loader to bulid in to train\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0  # Accumulator for epoch loss\n",
    "    correct_predictions = 0  # Counter for correct predictions\n",
    "    total_predictions = 0  # Counter for total predictions\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()  \n",
    "\n",
    "        # Calculate accuracy for this batch\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    average_epoch_loss = epoch_loss / len(train_loader)  # Calculate average loss for the epoch\n",
    "    accuracy = correct_predictions / total_predictions  # Calculate accuracy for the epoch\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {average_epoch_loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d38dba",
   "metadata": {},
   "source": [
    "### test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72d37bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.60%\n"
     ]
    }
   ],
   "source": [
    "# Define your test DataLoader (assuming you have a test_dataset)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Variables to keep track of correct and total predictions\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Iterate through the test data and calculate accuracy\n",
    "for inputs, targets in test_loader:\n",
    "    with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct_predictions += (predicted == targets).sum().item()\n",
    "    total_predictions += targets.size(0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059c6a1",
   "metadata": {},
   "source": [
    "#### the accuacy of train near accuarcy test but the sample 40% and more epoch as 50 not work in my pc "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
